# An Ensemble Model to Predict Preterm Birth Using Vaginal Microbiome Data
####  Jifan Gao<sup>1,2</sup>, Zhoujingpeng Wei<sup>1,2</sup> Guanhua Chen<sup>1,2</sup>, Zhengzheng Tang<sup>1,2</sup>
<sup>1</sup> Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison, Madison, Wisconsin, USA <br/>
<sup>2</sup> Contact: J.G. (jifan.gao@wisc.edu), Z.W. (zwei74@wisc.edu),  G.C. (gchen25@wisc.edu), Z.T. (ztang2@wisc.edu)

>### Abstract
> We built a LightGBM-based model for preterm birth prediction with an ensemble strategy tailored for vaginal microbiome data collected from multiple projects. <br/>

## Background/Introduction
The Preterm Birth Prediction - Microbiome DREAM Challenge has two tasks: 1) prediction of preterm birth and 2) prediction of early preterm birth  [1]. We focus on Task 1, which aims to identify women at high risk of preterm birth using vaginal microbiome data. Preterm is defined as birth prior to 37 weeks of gestation collected from pregnant people. The training set contains 3,578 specimens from 1,268 subjects across 10 different projects, of which 417 subjects delivered preterm. The test set is collected from an individual project and is unseen by challenge participants. The test set only includes specimens collected no later than 32 weeks of gestation.  Microbiome data has been processed, and the following types of data are accessible: 
1. Alpha-diversity metrics for each specimen.
2. Pairwise phylogenetic distance between specimens.
3. Counts and relative abundance of reads assigned to each phylotype within a specimen.
4. Counts of reads and relative abundance at the family level, genus level, or species level within a specimen.
5. Valencia Community state type for each specimen.
In addition, metadata such as the gestational week when the sample was collected, when the participant delivered, and demographics (maternal age or age range, race, ethnicity) are also available.  The area under the receiver operator characteristic curve (AUROC) is used as the primary evaluation metric, and the area under the precision-recall curve (AUPR) is used as the tie-breaker.

## Methods
### Feature Selection
We use specimens collected no later than 32 weeks of gestation for developing the prediction model. We extract microbiome data from *phylotype_nreads.5e_1.csv*, *phylotype_nreads.1e0.csv*, *taxonomy_nreads.species.csv*, *taxonomy_nreads.genus.csv*, *taxonomy_nreads.family.csv* tables. The *phylotype_nreads.1e_1.csv* table is not used because its number of columns (9,718) is overwhelming compared to the sample size. We remove taxa that don't have at least 5 nonzero observations in any of the studies of the training set. In addition, the *age*, *collect__wk*, *NIH Racial Category* columns from the *metadata.csv*, the *CST* and *subCST* columns from the *cst_valencia.csv*, and the *shannon*, *inv_simpson*, *bwpd*,  *phylo_entropy*, *quadratic*, *unrooted_pd*, and *rooted_pd* columns from the *alpha_diversity.csv* are also used as features.

### Data Transformation
We apply the centered log-ratio (clr) transformation [2] on microbiome data to obtain scale-invariant values. 
Clr transformation is applied to each taxon from *phylotype_nreads.5e_1.csv*, *phylotype_nreads.1e0.csv*, *taxonomy_nreads.species.csv*, *taxonomy_nreads.genus.csv*, *taxonomy_nreads.family.csv* tables as described in the previous section.

### Machine Learning Model
We use the LightGBM [3] as the prediction model due to its high performance in machine learning competitions. Each specimen is one training sample and has a total of 1,991 features. 5-fold cross-validation on the subject level is used to tune hyperparameters. We use Optuna [4] to enable automatic hyperparameter tuning. AUROC is used as the stop criteria.

### Model Ensemble
Since Project G has a mean sequencing depth (sum of raw counts) of 185,010, whereas the mean sequencing depths of other projects in the training set are below 50,000, we build two prediction models: one is trained using specimens from all projects (Model 1) and one is trained only using specimens from Project G (Model 2). When making a prediction given a specimen, the ensembling weights of Model 1 and Model 2 are generated by a logistic regression model with sequencing depth and collection week as features.

### Specimen Reweighting
In this challenge, one subject is likely to have multiple vaginal microbiome specimens. We use a customized weighting method to generate one prediction from multiple specimens on one subject. 
If a subject has multiple specimens, then the weight of each specimen = collect_wk / sum of collect_wks of specimens from the subject. For example, if a subject has specimens collected from Week 16, 24, and 30, then the corresponding weights are:
16/(16+24+30)=0.23, 24/(16+24+30)=0.34, 30/(16+24+30)=0.43. The more recent a specimen is collected, the more contribution it will make to the final prediction.

## Results
The model is ranked 1st place on Task 1's leaderboard based on the entire test set, although the AUROC and AUPR are unavailable according to the challenge rules. The estimated AUROC and AUPR based on 100 bootstrap iterations on a small subset of the test set are 0.6895 and 0.6264. 

## Discussion
We also use a similar workflow described in this write-up for Task 2. However, our best performance is only in the middle range on Task 2 's leaderboard. We plan to investigate what leads to performance differences between Tasks 1 and 2 in the future.

## References
[1] Sage Bionetworks. Preterm Birth Prediction - Microbiome DREAM Challenge, https://www.synapse.org/#!Synapse:syn26133770/wiki/. <br/>
[2] Aitchison, J. "Compositional Data Analysis." (1986). <br/>
[3] Ke G, Meng Q, Finley T, et al. Lightgbm: A highly efficient gradient boosting decision tree[C]//Advances in neural information processing systems. 2017: 3146-3154. <br/>
[4] Akiba T, Sano S, Yanase T, et al. Optuna: A next-generation hyperparameter optimization framework[C]//Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2019: 2623-2631. 

## Author Contributions
G.C., Z.T., J.G., and Z.W. designed the model and wrote the paper. J.G. and Z.W. implemented the code.
